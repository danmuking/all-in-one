## CAP理论
1. Consistent：一致性，指数据在多个副本之间能够保持一致的特性（严格的一致性）
2. Availability：可用性，指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据）
3. Partition tolerance：分区容忍性，分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障

CAP不可能同时满足，最多能够同时满足其中的两点。
## BASE理论
BASE是Base Available Soft State Eventually Consistent的缩写，可以认为是AP的延伸，通过允许短暂的不一致来尽可能满足CAP
## Paoxs算法
### 流程
阶段一

1. Proposer选择一个提案编号N，然后像半数以上的Acceptor发送编号为N的Prepare请求
2. 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过得所有Prepare请求的编号，那么他就会将已经接受过编号最大的提案作为响应返回给Proposer，同时承诺不在接收任何编号小于N提案。否则将不做响应或者返回error。

阶段二

1. 如果Proposer收到半数以上Accpetor对其编号为N提案的响应，那么他就会发送一个[N,V]的Accpet请求给半数以上的Acceptor，其中V是收到响应中编号最大提案的V。如果没有收到任何提案，那么V的值可以又Proposer决定。
2. 如果Accpetor收到一个针对编号N提案的Accpet请求，只要Accpetor没有对编号大于N的Prepare请求做出响应，它就应该接收该提案。
### Paoxs推导
目标

1. 只有被提出的value才能被选定。
2. 只有一个value被选定，并且
3. 如果某个进程认为某个value被选定了，那么这个value必须是真的被选定的那个。

推导

1. 只有一个Acceptor的情况：只要Acceptor接受它收到的第一个值，则该提案被选定，该提案里的value就是选定的value。但是如果Acceptor宕机，系统就无法工作。因此需要多个Acceptor
> P1：Acceptor必须接受它收到的第一个提案。

2. 多个Acceptor的情况，如果仅依靠P1将会出现问题，例如![1752522-a2449c74a784bd87.webp](https://raw.githubusercontent.com/danmuking/image/main/888dd82240bb70a567bedb83b945e86d.webp)因此我们需要加强条件，**一个提案被选定需要被半数以上Acceptor接受**。要满足这个条件，就要求一个Acceptor可以接受不只一个提案。这样子就有可能不满足“只有一个value被选定”这个目标。我们需要重新设计提案，给每个提案加上一个提案编号，表示提案被提出的顺序。令『**提案=提案编号+value**』。但是这样仍然无法保证“只有一个value被选定”这个目标。我们需要一个新的约束。
> P2：如果某个value为v的提案被选定了，那么每个编号更高的被选定提案的value必须也是v。

因为这个约束不便于实现，我们可以对其进行加强
> P2a：如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v。

但是这个约束下还可能存在这样一种情况![1752522-e517a6fd3d55e2c0.webp](https://raw.githubusercontent.com/danmuking/image/main/1c474d7b69f924082b3dd9f9affd33d7.webp)
因此我们需要继续加强P2a
> P2b：如果某个value为v的提案被选定了，那么之后任何Proposer提出的编号更高的提案的value必须也是v。

由于P2b不便于实现，我们通常采用P2c
> P2c：对于任意的N和V，如果提案[N, V]被提出，那么存在一个半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个：
> - S中每个Acceptor都没有接受过编号小于N的提案。
> - S中Acceptor接受过的最大编号的提案的value为V


## raft算法
leader：负责接受并分发请求的节点
follower：只接受leader发送的记录
candidate：可以成为leader的节点
任期：Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。
### leader选举
candidate获得多数选票后成为leader，同时在任期内定期发送心跳给follower节点，如果超时，则重新开始选举
#### 投票规则
Candidate首先会给自己投票，然后再向其他节点收集投票信息
节点首先会判断请求的term是否更大，不是则说明是旧消息，拒绝该请求。
如果任期Term相同，则比较index，index较大则为更加新的日志；如果任期Term不同，term更大的则为更新的消息。如果是更新的消息，则给Candidate投票。
### 日志同步
leader接收客户端请求后，向所有follower同步。
当这条日志被复制到大多数follower后，leader将日志应用到状态机，并向客户端返回结构

- 每个Leader在开始工作时，会维护 nextIndex[] 和 matchIndex[] 两个数组，分别记录了每个 Follower 下一个将要发送的日志 index 和已经匹配上的日志 index。
- 当Leader收到返回成功时，则更新两个数组，否则说明follower上相同位置的数据和Leader不一致，这时候Leader会减小nextIndex[i]的值重试，一直找到follower上两者一致的位置，然后从这个位置开始复制Leader的数据给follower，同时follower后续已有的数据会被清空。

没有复制成功的follower，leader将无限重试。
### 安全性保证
Raft算法中引入了如下两条规则，来确保了

- **已经commit的消息，一定会存在于后续的Leader节点上，并且绝对不会在后续操作中被删除。**
- 对于并未commit的消息，可能会丢失。
#### 多数投票规则
一个candidate必须获得集群中的多数投票，才能被选为Leader
对于每条commit过的消息，它必须是被复制到了集群中的多数节点
#### 提交规则
只要日志在多数结点上存在，那么 Leader 就可以提交该操作。但是**Raft额外限制了 Leader只对自己任期内的日志条目适用该规则，先前任期的条目只能由当前任期的提交而间接被提交。**
### 日志压缩
![](https://raw.githubusercontent.com/danmuking/image/main/c4344c087b1ec92ecfee7b7af5b272a1.png)
### 集群成员变更
#### 多节点联合共识
![](https://raw.githubusercontent.com/danmuking/image/main/46b41ac6a4497797e7675399db7a1455.png)
